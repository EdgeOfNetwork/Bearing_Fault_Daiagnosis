{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7129783153030180457\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7802454016\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9809636690929873186\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kWwitYWLoOAN"
   },
   "outputs": [],
   "source": [
    "# Data science libraries\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NwhSN8hejF33"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scaling(data):\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(data)\n",
    "  return scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cQ0esbxOoUHc"
   },
   "outputs": [],
   "source": [
    "#path = \"/content/drive/MyDrive/Bearing/bearing_test_1/\"\n",
    "df = pd.read_csv(\"bearing_concat.csv\")\n",
    "\n",
    "features = df.columns[:400]\n",
    "target = 'target'\n",
    "random_seed = 42\n",
    "\n",
    "## Split the data into train and validation set\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.20, random_state=random_seed, shuffle=True)\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "x_train = scaling(x_train)\n",
    "x_test = scaling(x_test)\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "n_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "NDXtiegVo00s"
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x) #여기서 뻑이났는데\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JCCDndvfpWKl"
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dSvMNyN89K8G"
   },
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "e9kgdZdUpXN8"
   },
   "outputs": [],
   "source": [
    "model = build_model(input_shape,head_size=256, num_heads=4,ff_dim=4,num_transformer_blocks=4,mlp_units=[128],mlp_dropout=0.4,dropout=0.25,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "36zvc2YL5FIy",
    "outputId": "fb848caf-8210-41a9-85b8-ab8889f03493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 400, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 400, 1)      2           ['input_5[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 400, 1)      7169        ['layer_normalization_32[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 400, 1)       0           ['multi_head_attention_16[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 400, 1)      0           ['dropout_36[0][0]',             \n",
      " ambda)                                                           'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 400, 1)      2           ['tf.__operators__.add_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 400, 4)       8           ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 400, 4)       0           ['conv1d_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 400, 1)       5           ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 400, 1)      0           ['conv1d_33[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 400, 1)      2           ['tf.__operators__.add_33[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 400, 1)      7169        ['layer_normalization_34[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 400, 1)       0           ['multi_head_attention_17[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 400, 1)      0           ['dropout_38[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 400, 1)      2           ['tf.__operators__.add_34[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 400, 4)       8           ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 400, 4)       0           ['conv1d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 400, 1)       5           ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 400, 1)      0           ['conv1d_35[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 400, 1)      2           ['tf.__operators__.add_35[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 400, 1)      7169        ['layer_normalization_36[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 400, 1)       0           ['multi_head_attention_18[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (TFOpL  (None, 400, 1)      0           ['dropout_40[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 400, 1)      2           ['tf.__operators__.add_36[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 400, 4)       8           ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 400, 4)       0           ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 400, 1)       5           ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (TFOpL  (None, 400, 1)      0           ['conv1d_37[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_36[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 400, 1)      2           ['tf.__operators__.add_37[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 400, 1)      7169        ['layer_normalization_38[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 400, 1)       0           ['multi_head_attention_19[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (TFOpL  (None, 400, 1)      0           ['dropout_42[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_37[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 400, 1)      2           ['tf.__operators__.add_38[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 400, 4)       8           ['layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 400, 4)       0           ['conv1d_38[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 400, 1)       5           ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (TFOpL  (None, 400, 1)      0           ['conv1d_39[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_38[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 400)         0           ['tf.__operators__.add_39[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          51328       ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 10)           1290        ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 81,362\n",
      "Trainable params: 81,362\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=[\"sparse_categorical_accuracy\"],)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x_train, y_train, validation_split=0.2, epochs=500, batch_size=115,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K34COUW6298u"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "08WUs5gGxi1t"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('transformer_encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3454,
     "status": "ok",
     "timestamp": 1645355577076,
     "user": {
      "displayName": "이서영",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08706917529998634867"
     },
     "user_tz": -540
    },
    "id": "Dfm3_Zh9xcz8",
    "outputId": "3263ff6e-56f9-439c-c4c4-8e5d4a2ace02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 20ms/step - loss: 0.3056 - sparse_categorical_accuracy: 0.9137\n",
      "\n",
      "loss_and_metrics : [0.30559566617012024, 0.9137499928474426]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1645355667249,
     "user": {
      "displayName": "이서영",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08706917529998634867"
     },
     "user_tz": -540
    },
    "id": "9mPgkrBQ1o91",
    "outputId": "7934e920-ddb6-4287-8c7b-b4f83efd08da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 =  0.9137499928474426 loss= 0.30559566617012024\n"
     ]
    }
   ],
   "source": [
    "print('정답률 = ', loss_and_metrics[1],'loss=', loss_and_metrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3k-Uxp2-2LqG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1645355783650,
     "user": {
      "displayName": "이서영",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08706917529998634867"
     },
     "user_tz": -540
    },
    "id": "teJWQzoQ1xl0",
    "outputId": "bc3fa59a-66f6-49af-f955-7d921334260b"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6428/3494517250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'upper left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1645355007600,
     "user": {
      "displayName": "이서영",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08706917529998634867"
     },
     "user_tz": -540
    },
    "id": "s55NhqaGxs9t",
    "outputId": "ee981564-39dc-48b8-d0f2-0b08ea9b26b3"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-cfec98d83639>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxhat_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxhat_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]\n",
    "\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdhtTdBbxtQn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMP2pJ5D5emP4Lvj79SRQZt",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "transformer_encoder_classify3_ford_engine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
